{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import convnext_base, ConvNeXt_Base_Weights\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from torchvision.datasets import CIFAR10\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.image_data import ImageClassificationDataset\n",
    "from src.quantize import cluster_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root=\"/mnt/ssd/ronak/datasets/cifar10/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "train_data = CIFAR10(root, download=True)\n",
    "test_data = CIFAR10(root, download=True, train=False)\n",
    "\n",
    "x = train_data.data\n",
    "y = np.array(train_data.targets)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59  43  50 ... 158 152 148]\n",
      " [ 16   0  18 ... 123 119 122]\n",
      " [ 25  16  49 ... 118 120 109]\n",
      " ...\n",
      " [208 201 198 ... 160  56  53]\n",
      " [180 173 186 ... 184  97  83]\n",
      " [177 168 179 ... 216 151 123]]\n",
      "(50000, 32, 32, 3)\n",
      "(50000,)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# x_train = np.tile(train_data.data[..., None], 3) / 255\n",
    "x_train = train_data.data\n",
    "y_train = np.array(train_data.targets)\n",
    "# x_test =  np.tile(test_data.data[..., None], 3) / 255\n",
    "x_test =  test_data.data\n",
    "y_test = np.array(test_data.targets)\n",
    "\n",
    "print(x_train[0, :, :, 0])\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(len(np.unique(y_train)))\n",
    "\n",
    "np.save(os.path.join(root, \"x_train.npy\"), x_train)\n",
    "np.save(os.path.join(root, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(root, \"x_test.npy\"), x_test)\n",
    "np.save(os.path.join(root, \"y_test.npy\"), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = x[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2, 2))\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ConvNeXt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/mnt/ssd/ronak/datasets/cifar10'\n",
    "DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronak/miniconda3/envs/dl/lib/python3.11/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/home/ronak/miniconda3/envs/dl/lib/python3.11/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/home/ronak/miniconda3/envs/dl/lib/python3.11/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/home/ronak/miniconda3/envs/dl/lib/python3.11/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n"
     ]
    }
   ],
   "source": [
    "model = convnext_base(weights=ConvNeXt_Base_Weights.IMAGENET1K_V1).to(DEVICE)\n",
    "train_nodes, eval_nodes = get_graph_node_names(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_nodes = {\n",
    "    # node_name: user-specified key for output dict\n",
    "    'avgpool': 'features',\n",
    "}\n",
    "body = create_feature_extractor(model, return_nodes=return_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "root = DATA_PATH\n",
    "\n",
    "x_train = np.transpose(np.load(os.path.join(root, \"x_train.npy\")), axes=[0, 3, 1, 2])\n",
    "y_train = np.load(os.path.join(root, \"y_train.npy\"))\n",
    "print(x_train.shape)\n",
    "\n",
    "batch_size = 256\n",
    "transforms = ConvNeXt_Base_Weights.IMAGENET1K_V1.transforms()\n",
    "train_dataset = ImageClassificationDataset(x_train, y_train, transforms)\n",
    "dataloader = DataLoader(\n",
    "    train_dataset, sampler=SequentialSampler(train_dataset), batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/ronak/miniconda3/envs/dl/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "196it [06:53,  2.11s/it]\n"
     ]
    }
   ],
   "source": [
    "all_image_features, all_labels, all_idx = [], [], []\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(dataloader)):\n",
    "        idx, images, labels = batch\n",
    "        image_features = body(images.to(DEVICE))['features'].squeeze()\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        all_image_features.append(image_features)\n",
    "        all_labels.append(labels)\n",
    "        all_idx.append(idx)\n",
    "        \n",
    "all_image_features = torch.cat(all_image_features).cpu().detach().numpy()\n",
    "all_labels = torch.cat(all_labels).cpu().detach().numpy()\n",
    "all_idx = torch.cat(all_idx).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_image_features, os.path.join(DATA_PATH, \"convnext_base_features.pt\"))\n",
    "torch.save(all_labels, os.path.join(DATA_PATH, \"convnext_base_labels.pt\"))\n",
    "torch.save(all_idx, os.path.join(DATA_PATH, \"convnext_base_idx.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 50\n",
    "SEED = 11182023\n",
    "DATASET = \"cifar10\"\n",
    "DATA_PATH = f'/mnt/ssd/ronak/datasets/{DATASET}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_features = torch.load(os.path.join(DATA_PATH, \"convnext_base_features.pt\"))\n",
    "all_labels = torch.load(os.path.join(DATA_PATH, \"convnext_base_labels.pt\"))\n",
    "all_idx = torch.load(os.path.join(DATA_PATH, \"convnext_base_idx.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 49997 49998 49999]\n",
      "(50000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "image_labels, image_cluster = cluster_feat(all_image_features, NUM_CLUSTERS, seed=SEED)\n",
    "\n",
    "label_to_idx = np.argsort(all_idx)\n",
    "print(all_idx[label_to_idx])\n",
    "\n",
    "# have the labels correspond to the indices in order.\n",
    "image_labels_sorted = image_labels[label_to_idx]\n",
    "class_labels_sorted = all_labels[label_to_idx]\n",
    "\n",
    "print(image_labels_sorted.shape)\n",
    "print(class_labels_sorted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"convnext_base\"\n",
    "save_dir = f'/mnt/ssd/ronak/datasets/{DATASET}/quantization/{model_name}_kmeans_{NUM_CLUSTERS}'\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(save_dir, f'image_labels.npy'), image_labels_sorted)\n",
    "np.save(os.path.join(save_dir, f'class_labels.npy'), class_labels_sorted)\n",
    "\n",
    "_, counts = np.unique(all_labels, return_counts=True)\n",
    "y_marginal = counts/np.sum(counts)\n",
    "x_marginal = image_cluster.marginal\n",
    "\n",
    "np.save(os.path.join(save_dir, f'image_marginal.npy'), x_marginal)\n",
    "np.save(os.path.join(save_dir, f'class_marginal.npy'), y_marginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
