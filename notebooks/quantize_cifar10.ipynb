{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import convnext_base, ConvNeXt_Base_Weights\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.image_data import ImageClassificationDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ConvNeXt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '/mnt/ssd/ronak/datasets/cifar10'\n",
    "DEVICE = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronak/miniconda3/envs/dl/lib/python3.11/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/home/ronak/miniconda3/envs/dl/lib/python3.11/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/home/ronak/miniconda3/envs/dl/lib/python3.11/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/home/ronak/miniconda3/envs/dl/lib/python3.11/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n"
     ]
    }
   ],
   "source": [
    "model = convnext_base(weights=ConvNeXt_Base_Weights.IMAGENET1K_V1).to(DEVICE)\n",
    "train_nodes, eval_nodes = get_graph_node_names(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_nodes = {\n",
    "    # node_name: user-specified key for output dict\n",
    "    'avgpool': 'features',\n",
    "}\n",
    "body = create_feature_extractor(model, return_nodes=return_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "root = DATA_PATH\n",
    "x_train = np.transpose(np.load(os.path.join(root, \"x_train.npy\")), axes=[0, 3, 1, 2])\n",
    "y_train = np.load(os.path.join(root, \"y_train.npy\"))\n",
    "print(x_train.shape)\n",
    "\n",
    "batch_size = 256\n",
    "transforms = ConvNeXt_Base_Weights.IMAGENET1K_V1.transforms()\n",
    "train_dataset = ImageClassificationDataset(x_train, y_train, transforms)\n",
    "dataloader = DataLoader(\n",
    "    train_dataset, sampler=SequentialSampler(train_dataset), batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/ronak/miniconda3/envs/dl/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "196it [06:56,  2.12s/it]\n"
     ]
    }
   ],
   "source": [
    "all_image_features, all_labels, all_idx = [], [], []\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(dataloader)):\n",
    "        idx, images, labels = batch\n",
    "        image_features = body(images.to(DEVICE))['features'].squeeze()\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        all_image_features.append(image_features)\n",
    "        all_labels.append(labels)\n",
    "        all_idx.append(idx)\n",
    "        \n",
    "all_image_features = torch.cat(all_image_features).cpu().detach().numpy()\n",
    "all_labels = torch.cat(all_labels).cpu().detach().numpy()\n",
    "all_idx = torch.cat(all_idx).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_image_features, os.path.join(DATA_PATH, \"convnext_base_features.pt\"))\n",
    "torch.save(all_labels, os.path.join(DATA_PATH, \"convnext_base_labels.pt\"))\n",
    "torch.save(all_idx, os.path.join(DATA_PATH, \"convnext_base_idx.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 25\n",
    "SEED = 11182023\n",
    "DATA_PATH = '/mnt/ssd/ronak/datasets/cifar10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_features = torch.load(os.path.join(DATA_PATH, \"convnext_base_features.pt\"))\n",
    "all_labels = torch.load(os.path.join(DATA_PATH, \"convnext_base_labels.pt\"))\n",
    "all_idx = torch.load(os.path.join(DATA_PATH, \"convnext_base_idx.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans(object):\n",
    "    \n",
    "    def __init__(self, norm, pca, idx, index, marginal):\n",
    "        self.norm = norm\n",
    "        self.pca = pca\n",
    "        self.idx = idx\n",
    "        self.index = index\n",
    "        self.marginal = marginal\n",
    "    \n",
    "    def clustering(self, features):\n",
    "        data = features\n",
    "        if self.norm in ['l2', 'l1']:\n",
    "            data = normalize(data, norm=self.norm, axis=1)\n",
    "        data = self.pca.transform(data)[:, :self.idx+1]\n",
    "        data = data.astype(np.float32)\n",
    "        _, labels = self.index.search(data, 1)\n",
    "        labels = labels.reshape(-1)\n",
    "        return labels\n",
    "\n",
    "\n",
    "def cluster_feat(features, num_clusters,\n",
    "                 norm='none', whiten=True,\n",
    "                 pca_max_data=-1,\n",
    "                 explained_variance=0.9,\n",
    "                 num_redo=5, max_iter=500, seed=0):\n",
    "    assert 0 < explained_variance < 1\n",
    "    assert norm in ['none', 'l2', 'l1', None]\n",
    "    data1 = features\n",
    "    if norm in ['l2', 'l1']:\n",
    "        data1 = normalize(data1, norm=norm, axis=1)\n",
    "    pca = PCA(n_components=None, whiten=whiten, random_state=seed+1)\n",
    "    if pca_max_data < 0 or pca_max_data >= data1.shape[0]:\n",
    "        pca.fit(data1)\n",
    "    elif 0 < pca_max_data < data1.shape[0]:\n",
    "        rng = np.random.RandomState(seed+5)\n",
    "        idxs = rng.choice(data1.shape[0], size=pca_max_data, replace=False)\n",
    "        pca.fit(data1[idxs])\n",
    "    else:\n",
    "        raise ValueError(f'Invalid argument pca_max_data={pca_max_data} with {data1.shape[0]} datapoints')\n",
    "    s = np.cumsum(pca.explained_variance_ratio_)\n",
    "    idx = np.argmax(s >= explained_variance)  # last index to consider\n",
    "    data1 = pca.transform(data1)[:, :idx+1]\n",
    "    # Cluster\n",
    "    data1 = data1.astype(np.float32)\n",
    "    kmeans = faiss.Kmeans(data1.shape[1], num_clusters, niter=max_iter,\n",
    "                          nredo=num_redo, update_index=True, seed=seed+2, min_points_per_centroid=50)\n",
    "    kmeans.train(data1)\n",
    "    index = kmeans.index\n",
    "    _, labels = index.search(data1, 1)\n",
    "    \n",
    "    # Drop clusters with low frequency\n",
    "    ids, counts = np.unique(labels, return_counts=True)\n",
    "    to_remove = ids[counts < 50]\n",
    "    if len(to_remove) > 0:\n",
    "        index.remove_ids(to_remove)\n",
    "        _, labels = index.search(data1, 1)\n",
    "    \n",
    "    _, counts = np.unique(labels, return_counts=True)\n",
    "    cluster = KMeans(norm, pca, idx, index, counts/np.sum(counts))\n",
    "    return labels.reshape(-1), cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 49997 49998 49999]\n",
      "(50000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "image_labels, image_cluster = cluster_feat(all_image_features, NUM_CLUSTERS, seed=SEED)\n",
    "\n",
    "label_to_idx = np.argsort(all_idx)\n",
    "print(all_idx[label_to_idx])\n",
    "\n",
    "# have the labels correspond to the indices in order.\n",
    "image_labels_sorted = image_labels[label_to_idx]\n",
    "class_labels_sorted = all_labels[label_to_idx]\n",
    "\n",
    "print(image_labels_sorted.shape)\n",
    "print(class_labels_sorted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"convnext_base\"\n",
    "dataset = \"cifar10\"\n",
    "save_dir = f'/mnt/ssd/ronak/datasets/{dataset}/quantization/{model_name}_kmeans_{NUM_CLUSTERS}'\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(save_dir, f'image_labels.npy'), image_labels_sorted)\n",
    "np.save(os.path.join(save_dir, f'class_labels.npy'), class_labels_sorted)\n",
    "\n",
    "_, counts = np.unique(all_labels, return_counts=True)\n",
    "y_marginal = counts/np.sum(counts)\n",
    "x_marginal = image_cluster.marginal\n",
    "\n",
    "np.save(os.path.join(save_dir, f'image_marginal.npy'), x_marginal)\n",
    "np.save(os.path.join(save_dir, f'class_marginal.npy'), y_marginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
