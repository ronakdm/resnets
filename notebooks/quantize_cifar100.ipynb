{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.datasets import CIFAR100\n",
    "from torchvision.models import convnext_base, ConvNeXt_Base_Weights\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.image_data import ImageClassificationDataset\n",
    "from src.quantize import cluster_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"cifar100\"\n",
    "DATA_PATH = f'/mnt/ssd/ronak/datasets/{DATASET}'\n",
    "root = DATA_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to /mnt/ssd/ronak/datasets/cifar100/cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 169001437/169001437 [00:03<00:00, 46138668.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /mnt/ssd/ronak/datasets/cifar100/cifar-100-python.tar.gz to /mnt/ssd/ronak/datasets/cifar100\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_data = CIFAR100(root, download=True)\n",
    "test_data = CIFAR100(root, download=True, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "x = train_data.data\n",
    "y = np.array(train_data.targets)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 255 ... 195 212 182]\n",
      " [255 254 254 ... 170 161 146]\n",
      " [255 254 255 ... 189 166 121]\n",
      " ...\n",
      " [148 142 140 ...  30  65  76]\n",
      " [122 120 126 ...  22  97 141]\n",
      " [ 87  88 101 ...  34 105 138]]\n",
      "(50000, 32, 32, 3)\n",
      "(50000,)\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "# x_train = np.tile(train_data.data[..., None], 3) / 255\n",
    "x_train = train_data.data\n",
    "y_train = np.array(train_data.targets)\n",
    "# x_test =  np.tile(test_data.data[..., None], 3) / 255\n",
    "x_test =  test_data.data\n",
    "y_test = np.array(test_data.targets)\n",
    "\n",
    "print(x_train[0, :, :, 0])\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(len(np.unique(y_train)))\n",
    "\n",
    "np.save(os.path.join(root, \"x_train.npy\"), x_train)\n",
    "np.save(os.path.join(root, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(root, \"x_test.npy\"), x_test)\n",
    "np.save(os.path.join(root, \"y_test.npy\"), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = x_train[0]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2, 2))\n",
    "ax.axis(\"off\")\n",
    "ax.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ConvNeXt Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ronak/miniconda3/envs/dl/lib/python3.11/site-packages/torch/overrides.py:110: UserWarning: 'has_cuda' is deprecated, please use 'torch.backends.cuda.is_built()'\n",
      "  torch.has_cuda,\n",
      "/home/ronak/miniconda3/envs/dl/lib/python3.11/site-packages/torch/overrides.py:111: UserWarning: 'has_cudnn' is deprecated, please use 'torch.backends.cudnn.is_available()'\n",
      "  torch.has_cudnn,\n",
      "/home/ronak/miniconda3/envs/dl/lib/python3.11/site-packages/torch/overrides.py:117: UserWarning: 'has_mps' is deprecated, please use 'torch.backends.mps.is_built()'\n",
      "  torch.has_mps,\n",
      "/home/ronak/miniconda3/envs/dl/lib/python3.11/site-packages/torch/overrides.py:118: UserWarning: 'has_mkldnn' is deprecated, please use 'torch.backends.mkldnn.is_available()'\n",
      "  torch.has_mkldnn,\n"
     ]
    }
   ],
   "source": [
    "model = convnext_base(weights=ConvNeXt_Base_Weights.IMAGENET1K_V1).to(DEVICE)\n",
    "train_nodes, eval_nodes = get_graph_node_names(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "return_nodes = {\n",
    "    # node_name: user-specified key for output dict\n",
    "    'avgpool': 'features',\n",
    "}\n",
    "body = create_feature_extractor(model, return_nodes=return_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "root = DATA_PATH\n",
    "\n",
    "x_train = np.transpose(np.load(os.path.join(root, \"x_train.npy\")), axes=[0, 3, 1, 2])\n",
    "y_train = np.load(os.path.join(root, \"y_train.npy\"))\n",
    "print(x_train.shape)\n",
    "\n",
    "batch_size = 256\n",
    "transforms = ConvNeXt_Base_Weights.IMAGENET1K_V1.transforms()\n",
    "train_dataset = ImageClassificationDataset(x_train, y_train, transforms)\n",
    "dataloader = DataLoader(\n",
    "    train_dataset, sampler=SequentialSampler(train_dataset), batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/ronak/miniconda3/envs/dl/lib/python3.11/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "196it [06:48,  2.08s/it]\n"
     ]
    }
   ],
   "source": [
    "all_image_features, all_labels, all_idx = [], [], []\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(dataloader)):\n",
    "        idx, images, labels = batch\n",
    "        image_features = body(images.to(DEVICE))['features'].squeeze()\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        all_image_features.append(image_features)\n",
    "        all_labels.append(labels)\n",
    "        all_idx.append(idx)\n",
    "        \n",
    "all_image_features = torch.cat(all_image_features).cpu().detach().numpy()\n",
    "all_labels = torch.cat(all_labels).cpu().detach().numpy()\n",
    "all_idx = torch.cat(all_idx).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(all_image_features, os.path.join(DATA_PATH, \"convnext_base_features.pt\"))\n",
    "torch.save(all_labels, os.path.join(DATA_PATH, \"convnext_base_labels.pt\"))\n",
    "torch.save(all_idx, os.path.join(DATA_PATH, \"convnext_base_idx.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLUSTERS = 100\n",
    "SEED = 11182023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_image_features = torch.load(os.path.join(DATA_PATH, \"convnext_base_features.pt\"))\n",
    "all_labels = torch.load(os.path.join(DATA_PATH, \"convnext_base_labels.pt\"))\n",
    "all_idx = torch.load(os.path.join(DATA_PATH, \"convnext_base_idx.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 49997 49998 49999]\n",
      "(50000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "image_labels, image_cluster = cluster_feat(all_image_features, NUM_CLUSTERS, seed=SEED)\n",
    "\n",
    "label_to_idx = np.argsort(all_idx)\n",
    "print(all_idx[label_to_idx])\n",
    "\n",
    "# have the labels correspond to the indices in order.\n",
    "image_labels_sorted = image_labels[label_to_idx]\n",
    "class_labels_sorted = all_labels[label_to_idx]\n",
    "\n",
    "print(image_labels_sorted.shape)\n",
    "print(class_labels_sorted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"convnext_base\"\n",
    "save_dir = f'/mnt/ssd/ronak/datasets/{DATASET}/quantization/{model_name}_kmeans_{NUM_CLUSTERS}'\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(save_dir, f'image_labels.npy'), image_labels_sorted)\n",
    "np.save(os.path.join(save_dir, f'class_labels.npy'), class_labels_sorted)\n",
    "\n",
    "_, counts = np.unique(all_labels, return_counts=True)\n",
    "y_marginal = counts/np.sum(counts)\n",
    "x_marginal = image_cluster.marginal\n",
    "\n",
    "np.save(os.path.join(save_dir, f'image_marginal.npy'), x_marginal)\n",
    "np.save(os.path.join(save_dir, f'class_marginal.npy'), y_marginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
