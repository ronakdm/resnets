{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import open_clip\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from src.text_data import TokenizedTextClassificationDataset\n",
    "from src.quantize import cluster_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"/mnt/ssd/ronak/datasets/sst2/\"\n",
    "DEVICE = 'cuda:0'\n",
    "MODEL_NAME = \"vit_b32_laion2b\"\n",
    "DATASET = \"sst2\"\n",
    "SEED = 11182023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load SST-2 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "train = load_dataset('sst2', split='train', cache_dir=DATA_PATH)\n",
    "val = load_dataset('sst2', split='validation', cache_dir=DATA_PATH)\n",
    "test = load_dataset('sst2', split='test', cache_dir=DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.array(test['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': Value(dtype='int32', id=None),\n",
       " 'sentence': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['negative', 'positive'], id=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.features\n",
    "type(train['sentence'])\n",
    "type(train['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CLIP Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
    "model.to(DEVICE)\n",
    "tokenizer = open_clip.get_tokenizer('ViT-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenized_dataset(dset):\n",
    "    texts = []\n",
    "    labels = torch.tensor(dset['label']).long()\n",
    "    for sent in tqdm(dset['sentence']):\n",
    "        texts.append(tokenizer(sent)[0])\n",
    "    texts = torch.stack(texts)\n",
    "    print(texts.shape)\n",
    "    print(labels.shape)\n",
    "    return texts.numpy(), labels.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67349/67349 [00:09<00:00, 7404.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([67349, 77])\n",
      "torch.Size([67349])\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = get_tokenized_dataset(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 872/872 [00:00<00:00, 4515.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([872, 77])\n",
      "torch.Size([872])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1821/1821 [00:00<00:00, 5026.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1821, 77])\n",
      "torch.Size([1821])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_val, y_val = get_tokenized_dataset(val)\n",
    "x_test, y_test = get_tokenized_dataset(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(DATA_PATH, \"x_train.npy\"), x_train)\n",
    "np.save(os.path.join(DATA_PATH, \"y_train.npy\"), y_train)\n",
    "np.save(os.path.join(DATA_PATH, \"x_val.npy\"),   x_val)\n",
    "np.save(os.path.join(DATA_PATH, \"y_val.npy\"),   y_val)\n",
    "np.save(os.path.join(DATA_PATH, \"x_test.npy\"),  x_test)\n",
    "np.save(os.path.join(DATA_PATH, \"y_test.npy\"),  y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use CLIP Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('ViT-B-32', pretrained='laion2b_s34b_b79k')\n",
    "model.to(DEVICE)\n",
    "tokenizer = open_clip.get_tokenizer('ViT-B-32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67349, 77)\n",
      "(67349,)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.load(os.path.join(DATA_PATH, \"x_train.npy\"))\n",
    "y_train = np.load(os.path.join(DATA_PATH, \"y_train.npy\"))\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "train_dataset = TokenizedTextClassificationDataset(x_train, y_train)\n",
    "dataloader = DataLoader(\n",
    "    train_dataset, sampler=SequentialSampler(train_dataset), batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "264it [01:15,  3.49it/s]\n"
     ]
    }
   ],
   "source": [
    "all_text_features, all_labels, all_idx = [], [], []\n",
    "with torch.no_grad():\n",
    "    for i, batch in tqdm(enumerate(dataloader)):\n",
    "        idx, texts, labels = batch\n",
    "        text_features = model.encode_text(texts.to(DEVICE))\n",
    "        text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "        all_text_features.append(text_features)\n",
    "        all_labels.append(labels)\n",
    "        all_idx.append(idx)\n",
    "        \n",
    "all_text_features = torch.cat(all_text_features).cpu().detach().numpy()\n",
    "all_labels = torch.cat(all_labels).cpu().detach().numpy()\n",
    "all_idx = torch.cat(all_idx).cpu().detach().numpy()\n",
    "\n",
    "torch.save(all_text_features, os.path.join(DATA_PATH, f\"{MODEL_NAME}_features.pt\"))\n",
    "torch.save(all_labels, os.path.join(DATA_PATH, f\"{MODEL_NAME}_labels.pt\"))\n",
    "torch.save(all_idx, os.path.join(DATA_PATH, f\"{MODEL_NAME}_idx.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text_features = torch.load(os.path.join(DATA_PATH, f\"{MODEL_NAME}_features.pt\"))\n",
    "all_labels = torch.load(os.path.join(DATA_PATH, f\"{MODEL_NAME}_labels.pt\"))\n",
    "all_idx = torch.load(os.path.join(DATA_PATH, f\"{MODEL_NAME}_idx.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 67346 67347 67348]\n",
      "(67349,)\n",
      "(67349,)\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 100\n",
    "\n",
    "text_labels, text_cluster = cluster_feat(all_text_features, num_clusters, seed=SEED)\n",
    "\n",
    "label_to_idx = np.argsort(all_idx)\n",
    "print(all_idx[label_to_idx])\n",
    "\n",
    "# have the labels correspond to the indices in order.\n",
    "text_labels_sorted = text_labels[label_to_idx]\n",
    "class_labels_sorted = all_labels[label_to_idx]\n",
    "\n",
    "print(text_labels_sorted.shape)\n",
    "print(class_labels_sorted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = f'/mnt/ssd/ronak/datasets/{DATASET}/quantization/{MODEL_NAME}_kmeans_{num_clusters}'\n",
    "\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "np.save(os.path.join(save_dir, f'text_labels.npy'), text_labels_sorted)\n",
    "np.save(os.path.join(save_dir, f'class_labels.npy'), class_labels_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49407\n"
     ]
    }
   ],
   "source": [
    "print(x_train.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[49406,  9379,   686, ...,     0,     0,     0],\n",
       "       [49406, 12844,   871, ...,     0,     0,     0],\n",
       "       [49406,   682,  3925, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [49406,   536, 16120, ...,     0,     0,     0],\n",
       "       [49406,   320,  6262, ...,     0,     0,     0],\n",
       "       [49406,   589,   686, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49407\n"
     ]
    }
   ],
   "source": [
    "x_test = np.load(os.path.join(DATA_PATH, \"x_test.npy\"))\n",
    "print(x_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
