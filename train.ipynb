{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from data import get_cifar10_loaders\n",
    "from models import MyrtleNet\n",
    "from helper import ExperimentHelper, TRAIN, VAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Logging.\n",
    "# saving model iterates\n",
    "\n",
    "# TODO: Learning rate schedule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"loss_curve\"\n",
    "model_name = \"myrtle_net\"\n",
    "experiment_id = \"001\"\n",
    "logs_dir = \"logs/\"\n",
    "output_dir = \"/mnt/hdd/ronak/cifar10_resnets\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "batch_size = 512\n",
    "lr = 3e-4\n",
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "50,000 training samples.\n",
      "10,000 test samples.\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, test_dataloader = get_cifar10_loaders(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyrtleNet().float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = ExperimentHelper(\n",
    "    epochs, \n",
    "    len(train_dataloader), \n",
    "    len(test_dataloader), \n",
    "    [\"loss\", \"accuracy\"],\n",
    "    experiment_name,\n",
    "    model_name,\n",
    "    experiment_id,\n",
    "    logs_dir,\n",
    "    output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(logits, labels):\n",
    "    return {\n",
    "        \"loss\": loss_func(logits, labels).item(),\n",
    "        \"accuracy\": (torch.sum(torch.argmax(logits, dim=1) == labels) / len(labels)).item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-05 13:05:49,774 [INFO] ============================================\n",
      "\n",
      "2023-02-05 13:05:49,775 [INFO] ======== Epoch 1 / 2 ========\n",
      "2023-02-05 13:05:49,777 [INFO] Training...\n",
      "2023-02-05 13:06:00,150 [INFO]   batch    40 /    98.    elapsed: 0:00:10.\n",
      "2023-02-05 13:06:10,081 [INFO]   batch    80 /    98.    elapsed: 0:00:20.\n",
      "2023-02-05 13:06:14,468 [INFO]   train loss: 1.298\n",
      "2023-02-05 13:06:14,469 [INFO]   train accuracy: 0.552\n",
      "\n",
      "2023-02-05 13:06:14,470 [INFO]   train epoch 0 took: 0:00:25\n",
      "\n",
      "2023-02-05 13:06:14,471 [INFO] Running validation...\n",
      "2023-02-05 13:06:16,123 [INFO]   validation loss: 0.943\n",
      "2023-02-05 13:06:16,124 [INFO]   validation accuracy: 0.667\n",
      "\n",
      "2023-02-05 13:06:16,154 [INFO]   validation epoch 0 took: 0:00:02\n",
      "\n",
      "2023-02-05 13:06:16,155 [INFO] ======== Epoch 2 / 2 ========\n",
      "2023-02-05 13:06:16,155 [INFO] Training...\n",
      "2023-02-05 13:06:26,137 [INFO]   batch    40 /    98.    elapsed: 0:00:10.\n",
      "2023-02-05 13:06:36,127 [INFO]   batch    80 /    98.    elapsed: 0:00:20.\n",
      "2023-02-05 13:06:40,543 [INFO]   train loss: 0.745\n",
      "2023-02-05 13:06:40,544 [INFO]   train accuracy: 0.743\n",
      "\n",
      "2023-02-05 13:06:40,545 [INFO]   train epoch 1 took: 0:00:24\n",
      "\n",
      "2023-02-05 13:06:40,546 [INFO] Running validation...\n",
      "2023-02-05 13:06:42,214 [INFO]   validation loss: 0.684\n",
      "2023-02-05 13:06:42,215 [INFO]   validation accuracy: 0.763\n",
      "\n",
      "2023-02-05 13:06:42,346 [INFO]   validation epoch 1 took: 0:00:02\n",
      "\n",
      "2023-02-05 13:06:42,347 [INFO] Training complete! Total time: 0:00:53\n"
     ]
    }
   ],
   "source": [
    "helper.start_experiment(model)\n",
    "for epoch in range(epochs):\n",
    "    helper.start_epoch(epoch, TRAIN)\n",
    "    for i, (x_batch, y_batch) in enumerate(train_dataloader):\n",
    "        helper.start_step(i)\n",
    "        model.zero_grad()\n",
    "        logits = model(x_batch.to(device))\n",
    "        loss = loss_func(logits, y_batch.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        helper.end_step(evaluate(logits, y_batch.to(device)))\n",
    "    helper.end_epoch(epoch)\n",
    "\n",
    "    helper.start_epoch(epoch, VAL)\n",
    "    with torch.no_grad():\n",
    "        for i, (x_batch, y_batch) in enumerate(test_dataloader):\n",
    "            helper.start_step(i)\n",
    "            logits = model(x_batch.to(device))\n",
    "            helper.end_step(evaluate(logits, y_batch.to(device)))\n",
    "    helper.end_epoch(epoch, model=model)\n",
    "helper.end_experiment()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "79c70c801e3f670de78f2bce2f341499f7441897db361a95a8aa5ccf5ca1ca57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
